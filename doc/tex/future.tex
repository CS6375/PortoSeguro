
\documentclass{standalone}

\begin{document}

\section{Future Work}

Though multiple models were compared in our experiments, the overall performance was not very good.
Our final score received on Kaggle was 0.277 in Gini score, using the Gradient Boosting model of Scikit-learn. The gold medal submission was 0.291. There was a great gap in between.

We believe our work can be further optimized in following aspects.

\subsubsection{Dimension Reduction}

In our preprocessing part, we calculated the correlation matrix to see the possible relations between features. As a result, we conclude that we cannot ignore any feature just by looking at the correlation matrix, since none of them are closely related. This decision can be made automatically using library.

Scikit-learn provide a \emph{Principal component analysis} (\verb|PCA|) library, performing linear dimensionality reduction using \emph{Singular Value Decomposition} of the data to project it to a lower dimensional space. We tried this library with a few experiments. Though the our result showed that there is still no clear separation between points, it is still a possible way to improve the final result.

Another method with great potential is t-Distributed Stochastic Neighbor Embedding (t-SNE)\cite{van2014accelerating}, a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets\cite{tsne}. Unlike PCA, t-SNE preserves the local structure of data points.
The problem with Scikit-learn implementation of t-SNE is its lack of memory optimization and running time is unbearably high. There are some optimized implementations in other language like Julia\cite{tsne:julia} and Java\cite{tsne:java}. Further works can try on these library for Dimension Reduction.

\subsubsection{More Powerful Library, Models and Machines}

The goodness of the implementation of library is vital in model's performance. It's meaningless to use the `best' model if the training phase lasts forever. Also, different libraries have implementation of same model with greatly differed efficiency.

In our experiment, besides the model listed above, we also tried the neural network model implemented in Scikit-learn, i.e., \verb|MLPClassifier|\cite{Scikit:nn} class. No matter what parameters we tried, the results were either the training phase was unbearably long, or the Gini scores were not better than just random guess. However, as the competition ended, it turned out that the second place model was built on deep learning neural network using a different library (Keras\cite{chollet2017keras}) based on tensorflow\cite{abadi2016tensorflow}.

Hence, a notable future work direction would be trying to build the model using more powerful library and models.

\end{document}